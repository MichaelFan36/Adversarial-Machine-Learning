{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ddc0b46e6b69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import torchvision.utils\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
    "class_idx = json.load(open(\"./data/imagenet_class_index.json\"))\n",
    "idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(), # ToTensor : [0, 255] -> [0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_folder_custom_label(root, transform, custom_label) :\n",
    "    \n",
    "    # custom_label\n",
    "    # type : List\n",
    "    # index -> label\n",
    "    # ex) ['tench', 'goldfish', 'great_white_shark', 'tiger_shark']\n",
    "    \n",
    "    old_data = dsets.ImageFolder(root = root, transform = transform)\n",
    "    old_classes = old_data.classes\n",
    "    \n",
    "    label2idx = {}\n",
    "    \n",
    "    for i, item in enumerate(idx2label) :\n",
    "        label2idx[item] = i\n",
    "    \n",
    "    new_data = dsets.ImageFolder(root = root, transform = transform, \n",
    "                                 target_transform = lambda x : custom_label.index(old_classes[x]))\n",
    "    new_data.classes = idx2label\n",
    "    new_data.class_to_idx = label2idx\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = image_folder_custom_label(root = './data/imagenet', transform = transform, custom_label = idx2label)\n",
    "normal_loader = Data.DataLoader(normal_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title):\n",
    "    npimg = img.numpy()\n",
    "    fig = plt.figure(figsize = (5, 15))\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_iter = iter(normal_loader)\n",
    "images, labels = normal_iter.next()\n",
    "\n",
    "print(\"True Image & True Label\")\n",
    "imshow(torchvision.utils.make_grid(images, normalize=True), [normal_data.classes[i] for i in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download the Inception v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.inception_v3(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"True Image & Predicted Label\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in normal_loader:\n",
    "    \n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += 1\n",
    "    correct += (pre == labels).sum()\n",
    "    \n",
    "    imshow(torchvision.utils.make_grid(images.cpu().data, normalize=True), [normal_data.classes[i] for i in pre])\n",
    "        \n",
    "print('Accuracy of test text: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adversarial Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\delta_{i} = \\frac{1}{2}(tanh(w_{i})+1)-x_i$$   \n",
    "$$minmize \\Vert \\frac{1}{2}(tanh(w)+1)-x\\Vert^2_2 + c\\cdot f(\\frac{1}{2}(tanh(w)+1))$$   \n",
    "$$f(x')=max(max\\{ Z(x')_i:i\\neq t \\} - Z(x')_t, -\\kappa) $$      \n",
    "\n",
    "* Notation - $w$ : modifier, $t$ : class that $x'$ will be classified, $\\kappa$ : confidence, $Z$ : classifier without last softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CW-L2 Attack\n",
    "# Based on the paper, i.e. not exact same version of the code on https://github.com/carlini/nn_robust_attacks\n",
    "# (1) Binary search method for c, (2) Optimization on tanh space, (3) Choosing method best l2 adversaries is NOT IN THIS CODE.\n",
    "def cw_l2_attack(model, images, labels, targeted=False, c=1e-4, kappa=0, max_iter=1000, learning_rate=0.01) :\n",
    "\n",
    "    images = images.to(device)     \n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Define f-function\n",
    "    def f(x) :\n",
    "\n",
    "        outputs = model(x)\n",
    "        one_hot_labels = torch.eye(len(outputs[0]))[labels].to(device)\n",
    "\n",
    "        i, _ = torch.max((1-one_hot_labels)*outputs, dim=1)\n",
    "        j = torch.masked_select(outputs, one_hot_labels.byte())\n",
    "        \n",
    "        # If targeted, optimize for making the other class most likely \n",
    "        if targeted :\n",
    "            return torch.clamp(i-j, min=-kappa)\n",
    "        \n",
    "        # If untargeted, optimize for making the other class most likely \n",
    "        else :\n",
    "            return torch.clamp(j-i, min=-kappa)\n",
    "    \n",
    "    w = torch.zeros_like(images, requires_grad=True).to(device)\n",
    "\n",
    "    optimizer = optim.Adam([w], lr=learning_rate)\n",
    "\n",
    "    prev = 1e10\n",
    "    \n",
    "    for step in range(max_iter) :\n",
    "\n",
    "        a = 1/2*(nn.Tanh()(w) + 1)\n",
    "\n",
    "        loss1 = nn.MSELoss(reduction='sum')(a, images)\n",
    "        loss2 = torch.sum(c*f(a))\n",
    "\n",
    "        cost = loss1 + loss2\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Early Stop when loss does not converge.\n",
    "        if step % (max_iter//10) == 0 :\n",
    "            if cost > prev :\n",
    "                print('Attack Stopped due to CONVERGENCE....')\n",
    "                return a\n",
    "            prev = cost\n",
    "        \n",
    "        print('- Learning Progress : %2.2f %%        ' %((step+1)/max_iter*100), end='\\r')\n",
    "\n",
    "    attack_images = 1/2*(nn.Tanh()(w) + 1)\n",
    "\n",
    "    return attack_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Attack Image & Predicted Label\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in normal_loader:\n",
    "    \n",
    "    images = cw_l2_attack(model, images, labels, targeted=False, c=0.1)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "\n",
    "    total += 1\n",
    "    correct += (pre == labels).sum()\n",
    "    \n",
    "    imshow(torchvision.utils.make_grid(images.cpu().data, normalize=True), [normal_data.classes[i] for i in pre])\n",
    "    \n",
    "print('Accuracy of test text: %f %%' % (100 * float(correct) / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
