{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numbers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=transform),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=transform),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hcriterion = nn.MSELoss()\n",
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "nb_digits = 10\n",
    "target_onehot = torch.FloatTensor(data.shape[0], nb_digits)\n",
    "output = torch.zeros([data.shape[0],10], dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(1, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.9378e-21, 1.6176e-17, 2.1277e-12, 2.8845e-11, 3.0276e-15, 5.9464e-15,\n",
      "         1.1716e-16, 1.4767e-15, 1.0000e+00, 3.2401e-13],\n",
      "        [9.9993e-01, 7.2634e-05, 1.8659e-13, 2.7619e-16, 7.6857e-11, 2.5519e-12,\n",
      "         4.8096e-08, 9.9961e-09, 4.3281e-26, 2.6818e-15]])\n",
      "tensor(1.)\n",
      "1: tensor([1.], dtype=torch.float64, requires_grad=True)\n",
      "gamma gradient: None\n",
      "2: tensor([1.], dtype=torch.float64, requires_grad=True)\n",
      "3: tensor([0.9970], dtype=torch.float64, requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cozyn\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([1, 10])) that is different to the input size (torch.Size([2, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "gamma = torch.ones(1, requires_grad=True, dtype = torch.double)\n",
    "optimizer = optim.Adam([gamma], lr=0.003)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "output = torch.tensor([[-2.4197e+01, -1.6696e+01, -4.9090e+00, -2.3021e+00, -1.1464e+01,\n",
    "         -1.0789e+01, -1.4716e+01, -1.2182e+01,  2.1967e+01, -6.7910e+00],[ 3.5568e+01,  2.6038e+01,  6.2582e+00, -2.5737e-01,  1.2279e+01,\n",
    "          8.8739e+00,  1.8718e+01,  1.7147e+01, -2.2834e+01,  2.0158e+00]])\n",
    "temp = torch.tensor([[ 3.5568e+01,  2.6038e+01,  6.2582e+00, -2.5737e-01,  1.2279e+01,\n",
    "          8.8739e+00,  1.8718e+01,  1.7147e+01, -2.2834e+01,  2.0158e+00]])\n",
    "one_hot = torch.DoubleTensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
    "\n",
    "output = F.softmax(output, dim = 1)\n",
    "print(output)\n",
    "print(torch.sum(output[0]))\n",
    "predicted = output + gamma * temp\n",
    "loss = criterion(predicted, one_hot)\n",
    "print(\"1:\", gamma)\n",
    "print(\"gamma gradient:\", gamma.retain_grad())\n",
    "loss.backward()\n",
    "print(\"2:\", gamma)\n",
    "optimizer.step()\n",
    "print(\"3:\", gamma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
