{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numbers\n",
    "\n",
    "import torchattacks\n",
    "from torchattacks import CW\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataset using torch dataloaders\n",
    "batch_size_train = 128\n",
    "batch_size_test = 1000\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))]) # Normalizing dataset\n",
    "\n",
    "# Training dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=transform),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "# Test dataset\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=transform),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "# Initialize GPU\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial model structure\n",
    "class HNet(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(HNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim = 1) # add this because I need one-hot label and MSE loss\n",
    "        return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submodel Structure for training residual\n",
    "class NHNet(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(NHNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim = 1) # add this because I need one-hot label and MSE loss\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize some data structures to store useful data\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the initial model\n",
    "initial_model = HNet()\n",
    "\n",
    "#Create the optimizer for the initial model\n",
    "optimizer = optim.Adam(initial_model.parameters(), lr=0.003)\n",
    "\n",
    "# Create Loss function for the intial model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "#Change model into cuda mode\n",
    "if torch.cuda.is_available():\n",
    "    initial_model = initial_model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Model Training Function\n",
    "def train(epoch):\n",
    "    initial_model.train()\n",
    "#     exp_lr_scheduler.step()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = initial_model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "        # torch.save(initial_model.state_dict(), 'C:/Users/cozyn/Desktop/Research/Adversarial-Machine-Learning/results/model.pth')\n",
    "        # torch.save(optimizer.state_dict(), 'C:/Users/cozyn/Desktop/Research/Adversarial-Machine-Learning/results/optimizer.pth')\n",
    "        if (batch_idx + 1)% 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial Model Evaluating Function\n",
    "def evaluate(data_loader):\n",
    "    initial_model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "        \n",
    "            output = initial_model(data)\n",
    "        \n",
    "            loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "    test_losses.append(loss)    \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Training\n",
    "n_epochs = 65\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)\n",
    "    evaluate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this model so that I dont have to train again in the future\n",
    "torch.save(initial_model, 'C:/Users/cozyn/OneDrive/Desktop/Research/Adversarial-Machine-Learning/results/initial_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from local file\n",
    "initial_model = torch.load('C:/Users/cozyn/OneDrive/Desktop/Research/Adversarial-Machine-Learning/results/initial_model.pth')\n",
    "initial_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to calculate mse residual based on the wiki\n",
    "def mseresidual(y, F):\n",
    "    residual = y - F\n",
    "    absolute = torch.abs(residual)\n",
    "    residual = residual / torch.max(absolute)\n",
    "    return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Function used to train and find optimal gamma for submodels\n",
    "#input: intial model that's already trained\n",
    "#M is number of submodels needed to be trained\n",
    "def GradientBoosting(initial_model, M):\n",
    "    gamma_exp = torch.ones([M], dtype = torch.float64) # used to hold the final optimized gamma\n",
    "    models = [] # used to hold all the models\n",
    "    residual_list = [] # used to hold the residual of each batch calculated\n",
    "    for m in range(M):\n",
    "        # Intialize submodels\n",
    "        Hmodel = NHNet()\n",
    "        Hcriterion = nn.MSELoss()\n",
    "        if torch.cuda.is_available():\n",
    "            Hmodel = Hmodel.cuda()\n",
    "            gamma_exp = gamma_exp.cuda()\n",
    "            Hcriterion = Hcriterion.cuda()\n",
    "            \n",
    "        # Start Training\n",
    "        epoch = 20\n",
    "        Hoptimizer = optim.Adam(Hmodel.parameters(), lr=0.001)\n",
    "        for i in range(epoch):\n",
    "            Hmodel.train()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = Variable(data), Variable(target)\n",
    "                # Create one-hot label target tensor\n",
    "                nb_digits = 10\n",
    "                target_onehot = torch.FloatTensor(data.shape[0], nb_digits)\n",
    "                if torch.cuda.is_available():\n",
    "                    data = data.cuda()\n",
    "                    target = target.cuda()\n",
    "                    target_onehot = target_onehot.cuda()\n",
    "                # Calculate F(x)\n",
    "                output = initial_model(data)\n",
    "                # Calculate the output from all the models\n",
    "                for j in range(m):\n",
    "                    model = models[j]\n",
    "                    if torch.cuda.is_available():\n",
    "                        output = output.cuda()\n",
    "                        model = model.cuda()\n",
    "                    output = output + gamma_exp[j] * model(data)\n",
    "#                 print(\"output is:\", output)\n",
    "                #Convert into Onehot label so that it would be able to calculate the residual\n",
    "                target = target.view(-1,1)\n",
    "                target_onehot.zero_()\n",
    "                target_onehot.scatter_(1, target, 1)\n",
    "                #Calculate Residual\n",
    "#                 print(\"target_onehot is:\", target_onehot)\n",
    "#                 print(\"output is:\", output)\n",
    "                residual = mseresidual(target_onehot, output)\n",
    "                houtput = Hmodel(data)\n",
    "#                 print(\"houtput is:\", houtput)\n",
    "                residual = residual.type(torch.cuda.FloatTensor)\n",
    "                houtput = houtput.type(torch.cuda.FloatTensor)\n",
    "                #Calculate the loss\n",
    "                loss = Hcriterion(houtput, residual)\n",
    "                Hoptimizer.zero_grad()\n",
    "                loss.backward(retain_graph = True)\n",
    "                Hoptimizer.step()\n",
    "                # Print out current Process\n",
    "#                 if (batch_idx + 1)% 100 == 0 and i % 10 == 0:\n",
    "                print('Train Epoch: Model Number: {} {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        m+1,i, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                        100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
    "        models.append(Hmodel)\n",
    "        \n",
    "        # Initialize a random gamma\n",
    "        gamma = torch.rand(1, requires_grad=True, device=\"cuda\")\n",
    "        Goptimizer = optim.Adam([gamma], lr=0.01)\n",
    "        Gcriterion = nn.MSELoss()\n",
    "        # Start finding the best gamma\n",
    "        for i in range(20):\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = Variable(data), Variable(target)\n",
    "                nb_digits = 10\n",
    "                target_onehot = torch.FloatTensor(data.shape[0], nb_digits)\n",
    "                if torch.cuda.is_available():\n",
    "                    data = data.cuda()\n",
    "                    target = target.cuda()\n",
    "                    target_onehot = target_onehot.cuda()\n",
    "                    Hmodel = Hmodel.cuda()\n",
    "                    gamma = gamma.cuda()\n",
    "                    \n",
    "                #Calculate the initial output\n",
    "                Goptimizer.zero_grad()  \n",
    "                output = initial_model(data)\n",
    "                #Calculate the final output by combining all previous models\n",
    "                for j in range(m):\n",
    "                    model = models[j]\n",
    "                    if torch.cuda.is_available():\n",
    "                        model = model.cuda()\n",
    "                        output = output.cuda()\n",
    "                        gamma_temp = gamma_exp[j]\n",
    "                        gamma_temp = gamma_temp.cuda()\n",
    "                    output = output + gamma_temp * model(data)\n",
    "                # Covert into one-hot label\n",
    "                target = target.view(-1,1)\n",
    "                target_onehot.zero_()\n",
    "                target_onehot.scatter_(1, target, 1)\n",
    "                # Get the currect model output\n",
    "                temp = Hmodel(data)\n",
    "                # Find the current ensemble model output\n",
    "                predicted = output + gamma * temp\n",
    "                # Calculate the loss\n",
    "                loss = Gcriterion(predicted, target_onehot)\n",
    "                loss.backward(retain_graph = True)\n",
    "                # Optimize the gamma\n",
    "                Goptimizer.step()  \n",
    "        gamma_exp[m] = gamma\n",
    "    print(gamma_exp)\n",
    "    return models, gamma_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_offset = 1e-20\n",
    "det_offset = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADPGradient(initial_model, M):\n",
    "    gamma_exp = torch.ones([M], dtype = torch.float64)\n",
    "    models = [] # used to hold all the models\n",
    "    residual_list = [] # used to hold the residual of each batch calculated\n",
    "    epoch = 20\n",
    "    for m in range(M):\n",
    "        # Intialize submodels\n",
    "        Hmodel = NHNet()\n",
    "        Hcriterion = nn.MSELoss()\n",
    "        if torch.cuda.is_available():\n",
    "            Hmodel = Hmodel.cuda()\n",
    "            gamma_exp = gamma_exp.cuda()\n",
    "            Hcriterion = Hcriterion.cuda()\n",
    "            params = []\n",
    "            params += list(Hmodel.parameters())\n",
    "            for j in models:\n",
    "                params += list(j.parameters())\n",
    "            Hoptimizer = optim.Adam(params, lr=0.001, weight_decay=1e-4, eps=1e-7)\n",
    "        for i in range(epoch):\n",
    "            Hmodel.train()\n",
    "            for j in models:\n",
    "                j.train()\n",
    "                \n",
    "            losses = 0\n",
    "            ce_losses = 0\n",
    "            ee_losses = 0\n",
    "            det_losses = 0\n",
    "            alpha = 2.0\n",
    "            beta = 0.5\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = Variable(data), Variable(target)\n",
    "                nb_digits = 10\n",
    "                target_onehot = torch.FloatTensor(data.shape[0], nb_digits)\n",
    "                if torch.cuda.is_available():\n",
    "                    data = data.cuda()\n",
    "                    target = target.cuda()\n",
    "                    target_onehot = target_onehot.cuda()\n",
    "                y_true = torch.zeros(data.size(0), nb_digits).cuda()\n",
    "                y_true.scatter_(1, target.view(-1,1), 1)\n",
    "                ce_loss = 0\n",
    "                mask_non_y_pred = []\n",
    "                ensemble_probs = 0\n",
    "                for k in range(m+1):\n",
    "                    output = initial_model(data)\n",
    "                    target = target.view(-1,1)\n",
    "                    target_onehot.zero_()\n",
    "                    target_onehot.scatter_(1, target, 1)\n",
    "                    for j in range(m):\n",
    "                        model = models[j]\n",
    "                        if torch.cuda.is_available():\n",
    "                            model = model.cuda()\n",
    "                            output = output.cuda()\n",
    "                            gamma_temp = gamma_exp[j]\n",
    "                            gamma_temp = gamma_temp.cuda()\n",
    "                        if k < m and j == k:\n",
    "                            residual = mseresidual(target_onehot, output)\n",
    "                            houtput = model(data)\n",
    "                            residual = residual.type(torch.cuda.FloatTensor)\n",
    "                            houtput = houtput.type(torch.cuda.FloatTensor)\n",
    "                            ce_loss += Hcriterion(houtput, residual)\n",
    "                            y_pred = F.softmax(output, dim=-1)\n",
    "#                             y_pred = torch.reshape(output,dim=-1)\n",
    "                            bool_R_y_true = torch.eq(torch.ones_like(y_true) - y_true, torch.ones_like(y_true))\n",
    "                            mask_non_y_pred.append(torch.masked_select(y_pred, bool_R_y_true).reshape(-1, nb_digits-1))\n",
    "                            ensemble_probs += y_pred\n",
    "                        output = output + gamma_temp * model(data)\n",
    "                    \n",
    "                    if k == m:\n",
    "                        residual = mseresidual(target_onehot, output)\n",
    "                        houtput = Hmodel(data)\n",
    "                        residual = residual.type(torch.cuda.FloatTensor)\n",
    "                        houtput = houtput.type(torch.cuda.FloatTensor)\n",
    "                        ce_loss += Hcriterion(houtput, residual)\n",
    "                        y_pred = F.softmax(output, dim=-1)\n",
    "#                         y_pred = torch.reshape(output,dim=-1)\n",
    "                        bool_R_y_true = torch.eq(torch.ones_like(y_true) - y_true, torch.ones_like(y_true))\n",
    "                        mask_non_y_pred.append(torch.masked_select(y_pred, bool_R_y_true).reshape(-1, nb_digits-1))\n",
    "                        ensemble_probs += y_pred\n",
    "\n",
    "                ensemble_probs = ensemble_probs / (m+1)\n",
    "                ensemble_entropy = torch.sum(-torch.mul(ensemble_probs, torch.log(ensemble_probs + log_offset)), dim=-1).mean()\n",
    "\n",
    "                mask_non_y_pred = torch.stack(mask_non_y_pred, dim=1)\n",
    "\n",
    "#                 print(\"mask_non_y_pred shape is:\", mask_non_y_pred.shape)\n",
    "                assert mask_non_y_pred.shape == (data.size(0), m+1, nb_digits-1)\n",
    "                mask_non_y_pred = mask_non_y_pred / torch.norm(mask_non_y_pred, p=2, dim=-1, keepdim=True)\n",
    "                matrix = torch.matmul(mask_non_y_pred, mask_non_y_pred.permute(0, 2, 1))\n",
    "                log_det = torch.logdet(matrix+det_offset*torch.eye((m+1), device=matrix.device).unsqueeze(0)).mean()\n",
    "\n",
    "                loss = ce_loss - alpha * ensemble_entropy - beta * log_det\n",
    "\n",
    "                Hoptimizer.zero_grad()\n",
    "                loss.backward(retain_graph = True)\n",
    "                Hoptimizer.step()\n",
    "                print('Train Epoch: Model Number: {} {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        m+1,i, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                        100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
    "        models.append(Hmodel)\n",
    "        \n",
    "            # Initialize a random gamma\n",
    "        gamma = torch.rand(1, requires_grad=True, device=\"cuda\")\n",
    "        Goptimizer = optim.Adam([gamma], lr=0.01)\n",
    "        Gcriterion = nn.MSELoss()\n",
    "        # Start finding the best gamma\n",
    "        for i in range(20):\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = Variable(data), Variable(target)\n",
    "                nb_digits = 10\n",
    "                target_onehot = torch.FloatTensor(data.shape[0], nb_digits)\n",
    "                if torch.cuda.is_available():\n",
    "                    data = data.cuda()\n",
    "                    target = target.cuda()\n",
    "                    target_onehot = target_onehot.cuda()\n",
    "                    Hmodel = Hmodel.cuda()\n",
    "                    gamma = gamma.cuda()\n",
    "                    \n",
    "                #Calculate the initial output\n",
    "                Goptimizer.zero_grad()  \n",
    "                output = initial_model(data)\n",
    "                #Calculate the final output by combining all previous models\n",
    "                for j in range(m):\n",
    "                    model = models[j]\n",
    "                    if torch.cuda.is_available():\n",
    "                        model = model.cuda()\n",
    "                        output = output.cuda()\n",
    "                        gamma_temp = gamma_exp[j]\n",
    "                        gamma_temp = gamma_temp.cuda()\n",
    "                    output = output + gamma_temp * model(data)\n",
    "                # Covert into one-hot label\n",
    "                target = target.view(-1,1)\n",
    "                target_onehot.zero_()\n",
    "                target_onehot.scatter_(1, target, 1)\n",
    "                # Get the currect model output\n",
    "                temp = Hmodel(data)\n",
    "                # Find the current ensemble model output\n",
    "                predicted = output + gamma * temp\n",
    "                # Calculate the loss\n",
    "                loss = Gcriterion(predicted, target_onehot)\n",
    "                loss.backward(retain_graph = True)\n",
    "                # Optimize the gamma\n",
    "                Goptimizer.step()  \n",
    "        gamma_exp[m] = gamma\n",
    "    print(gamma_exp)\n",
    "    return models, gamma_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_models = 3\n",
    "models, gamma_exp = GradientBoosting(initial_model, num_of_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_models = 3\n",
    "models, gamma_exp = ADPGradient(initial_model, num_of_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the models trained\n",
    "for i in range(num_of_models):\n",
    "    model = models[i]\n",
    "    torch.save(model, 'C:/Users/cozyn/OneDrive/Desktop/Research/Adversarial-Machine-Learning/results/model' + str(i) + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimized gamma\n",
    "torch.save(gamma_exp, 'C:/Users/cozyn/OneDrive/Desktop/Research/Adversarial-Machine-Learning/results/gamma_exp.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models from the local files\n",
    "num_of_models = 3\n",
    "models = []\n",
    "for x in range(num_of_models):\n",
    "    globals()['model%s' % x] = torch.load('C:/Users/cozyn/OneDrive/Desktop/Research/Adversarial-Machine-Learning/results/model' + str(1) + '.pth')\n",
    "    models.append(globals()['model%s' % x])\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the optimized gamma from the local files\n",
    "gamma_exp = torch.load('C:/Users/cozyn/OneDrive/Desktop/Research/Adversarial-Machine-Learning/results/gamma_exp.txt')\n",
    "print(gamma_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the accuracy of the ensemble model\n",
    "# initial_model = torch.load('C:/Users/cozyn/OneDrive/Desktop/Research/Adversarial-Machine-Learning/results/initial_model.pth')\n",
    "initial_model.eval()\n",
    "\n",
    "loss = 0\n",
    "correct = 0\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = initial_model(data)\n",
    "        for i in range(num_of_models):\n",
    "            model = models[i]\n",
    "            if torch.cuda.is_available():\n",
    "                model = model.cuda()\n",
    "                output = output.cuda()\n",
    "                gamma_temp = gamma_exp[i]\n",
    "                gamma_temp = gamma_temp.cuda()\n",
    "            output = output + gamma_temp * model(data)\n",
    "        loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "loss /= len(train_loader.dataset)  \n",
    "print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "    loss, correct, len(train_loader.dataset),\n",
    "    100. * correct / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack the initial model using CW attack\n",
    "initial_model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "cw_attack = CW(initial_model, c=1)\n",
    "\n",
    "for data, target in test_loader:\n",
    "\n",
    "        images = cw_attack(data, target).cuda()\n",
    "        outputs = initial_model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target.cuda()).sum()\n",
    "    \n",
    "print('Robust accuracy: %.2f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble CW attack\n",
    "class Attack_ensemble(object):\n",
    "    r\"\"\"\n",
    "    Base class for all attacks.\n",
    "    .. note::\n",
    "        It automatically set device to the device where given model is.\n",
    "        It temporarily changes the original model's training mode to `test`\n",
    "        by `.eval()` only during an attack process.\n",
    "    \"\"\"\n",
    "    def __init__(self, name, model, models, gamma):\n",
    "        r\"\"\"\n",
    "        Initializes internal attack state.\n",
    "        Arguments:\n",
    "            name (str) : name of an attack.\n",
    "            model (torch.nn.Module): model to attack.\n",
    "        \"\"\"\n",
    "\n",
    "        self.attack = name\n",
    "        self.model = model\n",
    "        self.models = models\n",
    "        self.gamma = gamma\n",
    "        self.model_name = str(model).split(\"(\")[0]\n",
    "\n",
    "        self.training = model.training\n",
    "        self.device = next(model.parameters()).device\n",
    "        \n",
    "        self._targeted = 1\n",
    "        self._attack_mode = 'original'\n",
    "        self._return_type = 'float'\n",
    "\n",
    "    def forward(self, *input):\n",
    "        r\"\"\"\n",
    "        It defines the computation performed at every call.\n",
    "        Should be overridden by all subclasses.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def set_attack_mode(self, mode):\n",
    "        r\"\"\"\n",
    "        Set the attack mode.\n",
    "  \n",
    "        Arguments:\n",
    "            mode (str) : 'original' (DEFAULT)\n",
    "                         'targeted' - Use input labels as targeted labels.\n",
    "                         'least_likely' - Use least likely labels as targeted labels.\n",
    "        \"\"\"\n",
    "        if self._attack_mode is 'only_original':\n",
    "            raise ValueError(\"Changing attack mode is not supported in this attack method.\")\n",
    "            \n",
    "        if mode==\"original\":\n",
    "            self._attack_mode = \"original\"\n",
    "            self._targeted = 1\n",
    "            self._transform_label = self._get_label\n",
    "        elif mode==\"targeted\":\n",
    "            self._attack_mode = \"targeted\"\n",
    "            self._targeted = -1\n",
    "            self._transform_label = self._get_label\n",
    "        elif mode==\"least_likely\":\n",
    "            self._attack_mode = \"least_likely\"\n",
    "            self._targeted = -1\n",
    "            self._transform_label = self._get_least_likely_label\n",
    "        else:\n",
    "            raise ValueError(mode + \" is not a valid mode. [Options : original, targeted, least_likely]\")\n",
    "            \n",
    "    def set_return_type(self, type):\n",
    "        r\"\"\"\n",
    "        Set the return type of adversarial images: `int` or `float`.\n",
    "        Arguments:\n",
    "            type (str) : 'float' or 'int'. (DEFAULT : 'float')\n",
    "        \"\"\"\n",
    "        if type == 'float':\n",
    "            self._return_type = 'float'\n",
    "        elif type == 'int':\n",
    "            self._return_type = 'int'\n",
    "        else:\n",
    "            raise ValueError(type + \" is not a valid type. [Options : float, int]\")\n",
    "\n",
    "    def save(self, save_path, data_loader, verbose=True):\n",
    "        r\"\"\"\n",
    "        Save adversarial images as torch.tensor from given torch.utils.data.DataLoader.\n",
    "        Arguments:\n",
    "            save_path (str) : save_path.\n",
    "            data_loader (torch.utils.data.DataLoader) : data loader.\n",
    "            verbose (bool) : True for displaying detailed information. (DEFAULT : True)\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        image_list = []\n",
    "        label_list = []\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        total_batch = len(data_loader)\n",
    "\n",
    "        for step, (images, labels) in enumerate(data_loader):\n",
    "            adv_images = self.__call__(images, labels)\n",
    "\n",
    "            image_list.append(adv_images.cpu())\n",
    "            label_list.append(labels.cpu())\n",
    "\n",
    "            if self._return_type == 'int':\n",
    "                adv_images = adv_images.float()/255\n",
    "\n",
    "            if verbose:\n",
    "                outputs = self.model(adv_images)\n",
    "                for i in range(len(self.models)):\n",
    "                    sub_model = self.models[i]\n",
    "                    outputs = outputs + self.gamma[i] * sub_model(adv_images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels.to(self.device)).sum()\n",
    "\n",
    "                acc = 100 * float(correct) / total\n",
    "                print('- Save Progress : %2.2f %% / Accuracy : %2.2f %%' % ((step+1)/total_batch*100, acc), end='\\r')\n",
    "\n",
    "        x = torch.cat(image_list, 0)\n",
    "        y = torch.cat(label_list, 0)\n",
    "        torch.save((x, y), save_path)\n",
    "        print('\\n- Save Complete!')\n",
    "\n",
    "        self._switch_model()\n",
    "        \n",
    "    def _transform_label(self, images, labels):\n",
    "        r\"\"\"\n",
    "        Function for changing the attack mode.\n",
    "        \"\"\"\n",
    "        return labels\n",
    "        \n",
    "    def _get_label(self, images, labels):\n",
    "        r\"\"\"\n",
    "        Function for changing the attack mode.\n",
    "        Return input labels.\n",
    "        \"\"\"\n",
    "        return labels\n",
    "    \n",
    "    def _get_least_likely_label(self, images, labels):\n",
    "        r\"\"\"\n",
    "        Function for changing the attack mode.\n",
    "        Return least likely labels.\n",
    "        \"\"\"\n",
    "        outputs = self.model(images)\n",
    "        for i in range(len(self.models)):\n",
    "            sub_model = self.models[i]\n",
    "            outputs = outputs + self.gamma[i] * sub_model(images)\n",
    "        _, labels = torch.min(outputs.data, 1)\n",
    "        labels = labels.detach_()\n",
    "        return labels\n",
    "    \n",
    "    def _to_uint(self, images):\n",
    "        r\"\"\"\n",
    "        Function for changing the return type.\n",
    "        Return images as int.\n",
    "        \"\"\"\n",
    "        return (images*255).type(torch.uint8)\n",
    "\n",
    "    def _switch_model(self):\n",
    "        r\"\"\"\n",
    "        Function for changing the training mode of the model.\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            self.model.train()\n",
    "            for i in range(len(self.models)):\n",
    "                self.models[i].train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            for i in range(len(self.models)):\n",
    "                self.models[i].eval()\n",
    "\n",
    "    def __str__(self):\n",
    "        info = self.__dict__.copy()\n",
    "        \n",
    "        del_keys = ['model', 'attack']\n",
    "        \n",
    "        for key in info.keys():\n",
    "            if key[0] == \"_\" :\n",
    "                del_keys.append(key)\n",
    "                \n",
    "        for key in del_keys:\n",
    "            del info[key]\n",
    "        \n",
    "        info['attack_mode'] = self._attack_mode\n",
    "        if info['attack_mode'] == 'only_original' :\n",
    "            info['attack_mode'] = 'original'\n",
    "            \n",
    "        info['return_type'] = self._return_type\n",
    "        \n",
    "        return self.attack + \"(\" + ', '.join('{}={}'.format(key, val) for key, val in info.items()) + \")\"\n",
    "\n",
    "    def __call__(self, *input, **kwargs):\n",
    "        self.model.eval()\n",
    "        for i in range(len(self.models)):\n",
    "            self.models[i].eval()\n",
    "        images = self.forward(*input, **kwargs)\n",
    "        self._switch_model()\n",
    "\n",
    "        if self._return_type == 'int':\n",
    "            images = self._to_uint(images)\n",
    "\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Ensemble CW Attack\n",
    "import warnings\n",
    "\n",
    "class CW_Ensemble(Attack_ensemble):\n",
    "    r\"\"\"\n",
    "    CW in the paper 'Towards Evaluating the Robustness of Neural Networks'\n",
    "    [https://arxiv.org/abs/1608.04644]\n",
    "    Distance Measure : L2\n",
    "        \n",
    "    Arguments:\n",
    "        model (nn.Module): model to attack.\n",
    "        c (float): c in the paper. parameter for box-constraint. (DEFALUT : 1e-4)    \n",
    "            :math:`minimize \\Vert\\frac{1}{2}(tanh(w)+1)-x\\Vert^2_2+c\\cdot f(\\frac{1}{2}(tanh(w)+1))`    \n",
    "        kappa (float): kappa (also written as 'confidence') in the paper. (DEFALUT : 0)\n",
    "            :math:`f(x')=max(max\\{Z(x')_i:i\\neq t\\} -Z(x')_t, - \\kappa)`\n",
    "        steps (int): number of steps. (DEFALUT : 1000)\n",
    "        lr (float): learning rate of the Adam optimizer. (DEFALUT : 0.01)\n",
    "        \n",
    "    .. warning:: With default c, you can't easily get adversarial images. Set higher c like 1.\n",
    "    \n",
    "    Shape:\n",
    "        - images: :math:`(N, C, H, W)` where `N = number of batches`, `C = number of channels`,        `H = height` and `W = width`. It must have a range [0, 1].\n",
    "        - labels: :math:`(N)` where each value :math:`y_i` is :math:`0 \\leq y_i \\leq` `number of labels`.\n",
    "        - output: :math:`(N, C, H, W)`.\n",
    "          \n",
    "    Examples::\n",
    "        >>> attack = torchattacks.CW(model, targeted=False, c=1e-4, kappa=0, steps=1000, lr=0.01)\n",
    "        >>> adv_images = attack(images, labels)\n",
    "        \n",
    "    .. note:: NOT IMPLEMENTED methods in the paper due to time consuming.\n",
    "    \n",
    "        (1) Binary search for c.\n",
    "        \n",
    "        (2) Choosing best L2 adversaries.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, models, gamma, c=1e-4, kappa=0, steps=1000, lr=0.01):\n",
    "        super(CW_Ensemble, self).__init__(\"CW\", model, models, gamma)\n",
    "        self.c = c\n",
    "        self.kappa = kappa\n",
    "        self.steps = steps\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, images, labels):\n",
    "        r\"\"\"\n",
    "        Overridden.\n",
    "        \"\"\"\n",
    "        images = images.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        labels = self._transform_label(images, labels)\n",
    "\n",
    "        # f-function in the paper\n",
    "        def f(x):\n",
    "            outputs = self.model(x)\n",
    "            for i in range(len(self.models)):\n",
    "                sub_model = self.models[i]\n",
    "                outputs = outputs + self.gamma[i] * sub_model(x)\n",
    "            one_hot_labels = torch.eye(len(outputs[0]))[labels].to(self.device)\n",
    "\n",
    "            i, _ = torch.max((1-one_hot_labels)*outputs, dim=1)\n",
    "            j = torch.masked_select(outputs, one_hot_labels.bool())\n",
    "\n",
    "            return torch.clamp(self._targeted*(j-i), min=-self.kappa)\n",
    "\n",
    "        w = torch.zeros_like(images).to(self.device)\n",
    "        w.detach_()\n",
    "        w.requires_grad = True\n",
    "\n",
    "        optimizer = optim.Adam([w], lr=self.lr)\n",
    "        prev = 1e10\n",
    "\n",
    "        for step in range(self.steps):\n",
    "\n",
    "            a = 1/2*(nn.Tanh()(w) + 1)\n",
    "\n",
    "            loss1 = nn.MSELoss(reduction='sum')(a, images)\n",
    "            loss2 = torch.sum(self.c*f(a))\n",
    "\n",
    "            cost = loss1 + loss2\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            cost.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Early Stop when loss does not converge.\n",
    "            if step % (self.steps//10) == 0:\n",
    "                if cost > prev:\n",
    "                    warnings.warn(\"Early stopped because the loss is not converged.\")\n",
    "                    return (1/2*(nn.Tanh()(w) + 1)).detach()\n",
    "                prev = cost\n",
    "\n",
    "            # print('- CW Attack Progress : %2.2f %%        ' %((step+1)/self.steps*100), end='\\r')\n",
    "\n",
    "        adv_images = (1/2*(nn.Tanh()(w) + 1)).detach()\n",
    "\n",
    "        return adv_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attack the ensemble model\n",
    "initial_model.eval()\n",
    "for i in range(num_of_models):\n",
    "    models[i].eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "cw_attack = CW_Ensemble(model = initial_model,models = models,gamma = gamma_exp, c=1)\n",
    "\n",
    "for data, target in test_loader:\n",
    "\n",
    "        images = cw_attack(data, target).cuda()\n",
    "        outputs = initial_model(images)\n",
    "        for i in range(num_of_models):\n",
    "            sub_model = models[i]\n",
    "            outputs = outputs + gamma_exp[i] * sub_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target.cuda()).sum()\n",
    "    \n",
    "print('Robust accuracy: %.2f %%' % (100 * float(correct) / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
